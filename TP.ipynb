{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc47ea2",
   "metadata": {},
   "source": [
    "# Tp Ciencia de datos 2025\n",
    "\n",
    "## Grupo 2\n",
    "**Integrantes:**\n",
    "- Francisco Lucich\n",
    "- Esteban Luna\n",
    "- Francisco Moretti\n",
    "- Tomás Zubik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2d31f",
   "metadata": {},
   "source": [
    "# Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17533d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos 'all' para obtener tanto el set de entrenamiento como el de test\n",
    "# Removemos headers, footers y quotes para simplificar el texto\n",
    "newsgroups_data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una lista donde cada elemento es el texto de un documento\n",
    "newsgroups_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f64509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un array de NumPy con números enteros que representan la categoría de cada documento.\n",
    "newsgroups_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una lista con los nombres correspondientes a cada número en .target.\n",
    "newsgroups_data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e7937",
   "metadata": {},
   "source": [
    "# Fase 1: Carga, Exploración Inicial y Limpieza Básica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a04865",
   "metadata": {},
   "source": [
    "**1: carga del dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77845dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Crear el DataFrame\n",
    "df = pd.DataFrame({'texto': newsgroups_data.data, 'target': newsgroups_data.target})\n",
    "# Mapear los números de target a los nombres de las categorías\n",
    "df['categoria'] = df['target'].apply(lambda i: newsgroups_data.target_names[i])\n",
    "# Ahora puedes descartar la columna 'target' si lo deseas\n",
    "# df = df.drop('target', axis=1)\n",
    "print(df.head())\n",
    "print(f\"Nombres de las categorías: {newsgroups_data.target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d564a4",
   "metadata": {},
   "source": [
    "**2: Exploracion inicial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dc1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e52079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ed735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.inspect() no existe result: AttributeError: 'DataFrame' object has no attribute 'inspect''ArithmeticError\n",
    "\n",
    "# describe() muestra estadísticas descriptivas de las columnas numéricas del DataFrame,\n",
    "# como media, desviación estándar, mínimos, máximos y percentiles.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f1b20",
   "metadata": {},
   "source": [
    "**2.1 analisis de categorias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función value_counts() cuenta la cantidad de ocurrencias de cada valor en una columna.\n",
    "#sort_index() ordena los resultados por el índice (en este caso, las categorías).\n",
    "df.value_counts('categoria').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade9136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización: Gráfico de barras de la distribución de documentos por categoría\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Contar documentos por categoría\n",
    "conteo_categorias = df['categoria'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=conteo_categorias.index, y=conteo_categorias.values, palette=\"viridis\")\n",
    "plt.xticks(rotation=90, ha='center')\n",
    "plt.yticks(range(0, conteo_categorias.max() + 100, 100))\n",
    "plt.xlabel('Categoría')\n",
    "plt.ylabel('Cantidad de documentos')\n",
    "plt.title('Distribución de documentos por categoría')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27ae5a",
   "metadata": {},
   "source": [
    "**3. limpieza basica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "df['texto_limpio'] = df['texto'].str.lower()  # Convertir a minúsculas\n",
    "\n",
    "df['texto_limpio'] = df['texto_limpio'].str.replace(r'\\d+', '', regex=True)  # Eliminar números\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)  # Crear un traductor para eliminar puntuación\n",
    "df['texto_limpio'] = df['texto_limpio'].apply(lambda x: x.translate(translator))  # Eliminar puntuación\n",
    "\n",
    "df['texto_limpio'] = df['texto_limpio'].str.replace(r'\\s+', ' ', regex=True)  # Eliminar espacios en blanco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texto_limpio'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738b8333",
   "metadata": {},
   "source": [
    "# Fase 2: Preprocesamiento con NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5673d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d1704",
   "metadata": {},
   "source": [
    "**1. Tokenizacion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens']= df['texto_limpio'].apply(nltk.word_tokenize)  # Tokenización\n",
    "\n",
    "df['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50a12c2",
   "metadata": {},
   "source": [
    "**2. Eliminacion de Stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8367a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_sin_stopwords'] = df['tokens'].apply(lambda x: [word for word in x if word not in nltk.corpus.stopwords.words('english')])\n",
    "df['tokens_sin_stopwords'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords_personalizadas = {'would', 'could', 'also', 'one', 'get', 'like', 'use', 'subject', 'writes', 'article'}\n",
    "\n",
    "# Unir ambas listas\n",
    "stopwords_actualizadas = stopwords.union(stopwords_personalizadas)\n",
    "\n",
    "# Aplicar la eliminación de stopwords (incluyendo las personalizadas)\n",
    "df['tokens_sin_stopwords'] = df['tokens'].apply(lambda x: [word for word in x if word not in stopwords_actualizadas])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80ed496",
   "metadata": {},
   "source": [
    "**2. Lematización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Inicializar el lematizador\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Aplicar lematización\n",
    "df['tokens_lematizados'] = df['tokens_sin_stopwords'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "df[['tokens_sin_stopwords', 'tokens_lematizados']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bb7145",
   "metadata": {},
   "source": [
    "*Comparación Lematización y Stemming*\n",
    "\n",
    "La lematización reduce las palabras a su forma base (lema) utilizando un enfoque basado en el significado y la gramática. Es más preciso pero más lento. Mientras que el stemming recorta las palabras a su raíz básica sin considerar el contexto gramatical. Es más rápido pero menos preciso.\n",
    "\n",
    "Usaríamos lemmatización cuando se necesita precisión y el significado de las palabras es importante (por ejemplo, análisis semántico), y stemming cuando se valora más la  velocidad y no importa perder algo de precisión (por ejemplo, motores de búsqueda)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8d87c",
   "metadata": {},
   "source": [
    "**4. Análisis de Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472cff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Combinar todos los tokens lematizados en una sola lista\n",
    "\n",
    "todos_los_tokens = [token for tokens in df['tokens_lematizados'] for token in tokens]\n",
    "\n",
    "# Calcular la frecuencia de cada token\n",
    "frecuencia_tokens = FreqDist(todos_los_tokens)\n",
    "\n",
    "tokens_mas_frecuentes = frecuencia_tokens.most_common(30)\n",
    "print(\"Tokens más frecuentes:\", tokens_mas_frecuentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preparar datos para el gráfico\n",
    "tokens, frecuencias = zip(*tokens_mas_frecuentes)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=list(tokens), y=list(frecuencias), palette=\"viridis\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Tokens más frecuentes después del preprocesamiento')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f958d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una función para calcular frecuencias por categoría\n",
    "def frecuencia_por_categoria(categoria):\n",
    "    tokens_categoria = [token for tokens in df[df['categoria'] == categoria]['tokens_lematizados'] for token in tokens]\n",
    "    return FreqDist(tokens_categoria)\n",
    "\n",
    "# Seleccionar algunas categorías para análisis\n",
    "categorias_seleccionadas = df['categoria'].unique()[:5] \n",
    "\n",
    "for categoria in categorias_seleccionadas:\n",
    "    frecuencia_categoria = frecuencia_por_categoria(categoria)\n",
    "    tokens_categoria, frecuencias_categoria = zip(*frecuencia_categoria.most_common(10))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=list(tokens_categoria), y=list(frecuencias_categoria), palette=\"viridis\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Tokens')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title(f'Tokens más frecuentes en la categoría: {categoria}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413f3d3c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
